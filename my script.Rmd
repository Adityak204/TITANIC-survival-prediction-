---
title: "Survival Prediction , Titanic"
author: "Aditya Kumar Singh"
date: "July 29, 2016"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Welcome to my script
The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.

One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.

In this script, I'm trying to analyze what sorts of people were likely to survive.
I'm using logistic regression technique for modelling.

##Libraries used
```{r library}
library(Amelia)
library(ROCR)
```
 
 
 
##Importing dataset 
```{r}
train <- read.csv("train.csv" , na.strings = "")
test <- read.csv("test.csv" , na.strings = "")
op <- read.csv("genderclassmodel.csv")

```

##Cleaning Dataset
#Checking for missing values
**Training set**
```{r}
missmap(train)
```
**Test set ***
```{r}
missmap(test)
```
We can see the variable cabin has too many missing values, we will not use it. We will also drop PassengerId since it is only an index and Ticket.

```{r}
train <- train[,-c(1,4,9,11)]
test<- test[,-c(1,3,8,10)]
op <- read.csv("genderclassmodel.csv")
test <- cbind(op$Survived , test)
colnames(test)[[1]] <- "Survived"
```

In age column we will try to fill the empty columns using averaging technique.

```{r}
train$Age[is.na(train$Age)] <- mean(train$Age , na.rm = T)
test$Age[is.na(test$Age)] <- mean(test$Age , na.rm = T)
train <- na.omit(train)

```

We can see the pattern of distribution between all variables and output

```{r }
plot(train)
```

## Creating Model
We will be building few models and will select the best model on the basis of AIC score which will help us in getting an idea that how our model will perfrom on a value outside of training set
```{r}
model1 <- glm(Survived~. , data = train , family = binomial )
summary(model1)

model2 <- glm(Survived~Pclass+Sex+Age+SibSp , data = train , family = binomial )
summary(model2)


model3 <- glm(Survived~Pclass+Sex+Age+SibSp+Age:Sex , data = train , family = binomial )
summary(model3)

```

We can see model3 has lowest AIC so we will go forward with it

## Building ROC curve to access the model perfromance 
```{r}
p <- predict(model3 , newdata = test , type = "response" )
pr <- prediction(p, test$Survived)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc


```



##Prediction and checking model accuracy
We will be making prediction using our model and will be trying out various thresholds to improve the model accuracy. We will make use of F score(recall,Precision) to compute the threshold


```{r}
p <- predict(model3 , newdata = test , type = "response" )
pred <- ifelse(p>= 0.5, 1 ,0)
result <- cbind(pred , test$Survived)
a1<- table(test$Survived, pred)
a1

p <- predict(model3 , newdata = test , type = "response" )
pred <- ifelse(p>= 0.55, 1 ,0)
result <- cbind(pred , test$Survived)
a2<- table(test$Survived, pred)
a2

p <- predict(model3 , newdata = test , type = "response" )
pred <- ifelse(p>= 0.6, 1 ,0)
result <- cbind(pred , test$Survived)
a3<- table(test$Survived, pred)
a3

#Computing Fscores for each

Fscore_a1 <- 0.895
Fscore_a2 <- 0.933
Fscore_a1 <- 0.916


```

Threshold= 0.55 has the highest F score so we will select 0.55 as the threshold value for our model. Lets see the accuracy at this threshold
#Accuracy
```{r}
#accuracy = (TP + TN)/(Total no.of observations)
accuracy <- 0.9521
```





